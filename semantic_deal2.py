# é—®é¢˜ ğŸ™‹ åˆ†æä¸€å¥è¯/æ®µè½/ä¸€æœ¬ä¹¦ æ˜¯ç§¯æçš„ è¿˜æ˜¯æ¶ˆæçš„

# ä¸‹é¢è¿™äº›æ˜¯ åŸæ¥çš„åŸºç¡€éƒ¨åˆ†
# load the book
with open('miracle_in_the_andes.txt') as file:
    book = file.read()

import re
d = {}
pattern3 = re.compile('[a-zA-Z]+')
findings3 = re.findall(pattern3, book.lower())
for word in findings3:
    if word in d.keys():
        d[word] = d[word] + 1
    else:
        d[word] = 1

d_list = [(value, key) for (key, value) in d.items()]
d_list = sorted(d_list, reverse=True)
d_list[:5]
# print(d_list) # [(5346, 'the'), (2795, 'and'), (2729, 'i'), (2400, 'to'),

# é—®é¢˜ğŸ™‹
# åˆšæ‰çš„é—®é¢˜æ˜¯ æ­£åˆ™æ— æ³• åˆ†è¾¨é‚£äº›æ˜¯çœŸçš„å•è¯ï¼Œ æ¯”å¦‚ i u è¿™ç§æ— æ³•åŒºåˆ«
# ä½¿ç”¨ nltk æ¥è§£å†³è¿™ä¸ªé—®é¢˜

# load the book
with open('miracle_in_the_andes.txt') as file:
    book = file.read()

import re
d = {}
pattern3 = re.compile('[a-zA-Z]+')
findings3 = re.findall(pattern3, book.lower())
for word in findings3:
    if word in d.keys():
        d[word] = d[word] + 1
    else:
        d[word] = 1

d_list = [(value, key) for (key, value) in d.items()]
d_list = sorted(d_list, reverse=True)
d_list[:5]
# print(d_list) # [(5346, 'the'), (2795, 'and'), (2729, 'i'), ...

import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk.data import find

# æ˜¾ç¤ºNLTKæ•°æ®è·¯å¾„
# print(nltk.data.path)

# å°†ä¸‹è½½çš„VADERè¯å…¸æ–‡ä»¶æ”¾ç½®åˆ°ä¸Šè¿°è·¯å¾„ä¸­çš„ä¸€ä¸ªç›®å½•ä¸‹ï¼Œä¾‹å¦‚ `~/nltk_data/sentiment/`
nltk.data.path.append('nltk_data')

# æ£€æŸ¥VADERè¯å…¸æ˜¯å¦å­˜åœ¨
try:
    find('sentiment/vader_lexicon.zip')
    print("VADER lexicon found")
except LookupError:
    print("VADER lexicon not found")

# å®ä¾‹åŒ–æƒ…æ„Ÿåˆ†æå™¨
analyzer = SentimentIntensityAnalyzer()
# scores = analyzer.polarity_scores('hhaha, I am happy')
# print('scores', scores)
# neg æ˜¯æ¶ˆæåˆ†
# pos æ˜¯ç§¯æåˆ†
# neu æ˜¯ä¸­æ€§åˆ†
# compound æ˜¯ ç»¼åˆåˆ†

# å®šä¹‰ä¸ºç§¯æ  pos > neg  /  compound > 0
# scores {'neg': 0.0, 'neu': 0.351, 'pos': 0.649, 'compound': 0.5719}

# if scores['pos'] > scores['neg']:
#     print('It is a positive text')
# else:
#     print('It is a negative text')

# åˆ†æä¸€æœ¬ä¹¦æ˜¯ ç§¯æçš„è¿˜æ˜¯æ¶ˆæçš„
analyzerBook = analyzer.polarity_scores(book)
# print(analyzerBook)
# {'neg': 0.116, 'neu': 0.76, 'pos': 0.125, 'compound': 1.0}

# æ®µè½åˆ†æ
import re
pattern4 = re.compile('Chapter [0-9]+')
chapters = re.split(pattern4, book)
# print(len(chapters)) # åªæœ‰10æ®µ ä½†æ‰“å‡º 11 æœ‰ ''
chapters = chapters[1:] # ä»ç¬¬ä¸€ä¸ª å¼€å§‹
for chapter in chapters:
    scores = analyzer.polarity_scores(chapter)
    # print(scores)
# æ‰“å°æ¯ä¸ªæ®µè½çš„ æƒ…æ„Ÿ  æ•°å€¼
# {'neg': 0.061, 'neu': 0.779, 'pos': 0.16, 'compound': 1.0}
# {'neg': 0.12, 'neu': 0.726, 'pos': 0.154, 'compound': 0.9991}
# {'neg': 0.145, 'neu': 0.751, 'pos': 0.105, 'compound': -0.9999}
# {'neg': 0.141, 'neu': 0.721, 'pos': 0.138, 'compound': -0.9963}
# {'neg': 0.118, 'neu': 0.742, 'pos': 0.141, 'compound': 0.9997}
# {'neg': 0.124, 'neu': 0.761, 'pos': 0.115, 'compound': -0.9979}
# {'neg': 0.136, 'neu': 0.761, 'pos': 0.103, 'compound': -0.9999}
# {'neg': 0.12, 'neu': 0.786, 'pos': 0.094, 'compound': -0.9998}
# {'neg': 0.097, 'neu': 0.824, 'pos': 0.079, 'compound': -0.9996}
# {'neg': 0.086, 'neu': 0.733, 'pos': 0.181, 'compound': 1.0}


# å¸¦ä¸Šç« èŠ‚ç¼–å·
for nr,chapter in enumerate(chapters):
    scores = analyzer.polarity_scores(chapter)
    print(nr + 1, scores)
# 1 {'neg': 0.061, 'neu': 0.779, 'pos': 0.16, 'compound': 1.0}
# 2 {'neg': 0.12, 'neu': 0.726, 'pos': 0.154, 'compound': 0.9991}
# ...